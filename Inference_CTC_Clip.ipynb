{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a28v99O3IzOm",
        "outputId": "21f5a0d1-37fa-4ae0-8aba-06ba51c0a321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Handwritten-Mathematical-Expression-Recognition'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 64 (delta 9), reused 55 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (64/64), 10.68 MiB | 15.85 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/Handwritten-Mathematical-Expression-Recognition\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pattan99/Handwritten-Mathematical-Expression-Recognition.git\n",
        "%cd Handwritten-Mathematical-Expression-Recognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyZHUd4gI8b_",
        "outputId": "97464bfb-8808-43d5-cf43-737d1e6bcd3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (5.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2024.11.6)\n",
            "Collecting ftfy (from -r requirements.txt (line 3))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting jiwer (from -r requirements.txt (line 4))\n",
            "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 1)) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 3)) (0.2.13)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer->-r requirements.txt (line 4)) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer->-r requirements.txt (line 4))\n",
            "  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 1)) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 1)) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 1)) (1.7.1)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
            "Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, ftfy, jiwer\n",
            "Successfully installed ftfy-6.3.1 jiwer-3.0.5 rapidfuzz-3.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!mkdir data/mathwriting-2024\n",
        "\n",
        "# !gdown \"https://drive.google.com/uc?id=1M8nyh6Lg5V1z7m4Mn2Lo5BiD0EbIcAAV\"\n",
        "# !gdown \"https://drive.google.com/uc?id=1wZEcyfDHSNVagh4dOJCtvCo_3JQ5pwEX\"\n",
        "!gdown \"https://drive.google.com/uc?id=1VYZErLFOZ-ZbfDhsGm40OV2O9Fui6T_a\"\n",
        "\n",
        "# !mv train.zip data/mathwriting-2024\n",
        "# !mv val.zip data/mathwriting-2024\n",
        "!mv test.zip data/mathwriting-2024\n",
        "\n",
        "# !unzip data/mathwriting-2024/train.zip -d data/mathwriting-2024\n",
        "# !unzip data/mathwriting-2024/val.zip -d data/mathwriting-2024\n",
        "!unzip data/mathwriting-2024/test.zip -d data/mathwriting-2024"
      ],
      "metadata": {
        "id": "F3vZkzH1JCZP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# !gdown --id 1ROWlHZpVfcIVEh8NQkZHl2LXPuvL7VRK\n",
        "# !gdown --id 1Y5G3xnODYhnl401sqxRaElpcOYtSfFiX\n",
        "!gdown --id 1E2UHNkvKcZCQ2DHUFGDmatmzYfIUuOuJ\n",
        "\n",
        "# !mv train_img.zip data/\n",
        "# !mv valid_img.zip data/\n",
        "!mv test_img.zip data/\n",
        "\n",
        "# !unzip data/train_img.zip -d data/\n",
        "# !unzip data/valid_img.zip -d data/\n",
        "!unzip data/test_img.zip -d data/"
      ],
      "metadata": {
        "id": "MzruIV26JOO7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "MATHWRITING_ROOT_DIR='data/mathwriting-2024'\n",
        "TRAIN_DIR = os.path.join(MATHWRITING_ROOT_DIR, 'train')\n",
        "VAL_DIR = os.path.join(MATHWRITING_ROOT_DIR, 'valid')\n",
        "TEST_DIR = os.path.join(MATHWRITING_ROOT_DIR, 'test')\n",
        "SYMBOL_DIR = os.path.join(MATHWRITING_ROOT_DIR, 'symbols')"
      ],
      "metadata": {
        "id": "4HGfnlZdJRLS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "train_df['file_path'] = train_df['file_path'].apply(lambda x: MATHWRITING_ROOT_DIR+'/'+x.split('/')[-2]+'/'+x.split('/')[-1].replace('.inkml','.bin'))\n",
        "train_df['image_path'] = train_df['file_path'].apply(lambda x: x.replace('train', 'train_img').replace('.bin','.png'))\n",
        "# train_df['file_path'] = train_df['file_path'].apply(lambda x: x.replace('train', 'train_merged'))\n",
        "\n",
        "valid_df = pd.read_csv(\"data/val.csv\")\n",
        "valid_df['file_path'] = valid_df['file_path'].apply(lambda x: MATHWRITING_ROOT_DIR+'/'+x.split('/')[-2]+'/'+x.split('/')[-1].replace('.inkml','.bin'))\n",
        "valid_df['image_path'] = valid_df['file_path'].apply(lambda x: x.replace('valid', 'valid_img').replace('.bin','.png'))\n",
        "valid_df['file_path'] = valid_df['file_path'].apply(lambda x: x.replace('valid', 'val'))\n",
        "\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "test_df['file_path'] = test_df['file_path'].apply(lambda x: MATHWRITING_ROOT_DIR+'/'+x.split('/')[-2]+'/'+x.split('/')[-1].replace('.inkml','.bin'))\n",
        "test_df['image_path'] = test_df['file_path'].apply(lambda x: x.replace('test', 'test_img').replace('.bin','.png'))\n",
        "# test_df['file_path'] = test_df['file_path'].apply(lambda x: x.replace('test', 'test_merged'))"
      ],
      "metadata": {
        "id": "fjSU9JZFJZ8W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from dataloader import StrokeDataset, collate_fn"
      ],
      "metadata": {
        "id": "EsDz8J_VJcu9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = StrokeDataset(data_dir=MATHWRITING_ROOT_DIR, labels_df=train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "valid_dataset = StrokeDataset(data_dir=MATHWRITING_ROOT_DIR, labels_df=test_df)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=2, collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrwUSSFnJhQk",
        "outputId": "e68ac12f-0069-41a1-ef31-70c692c8d2cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 257\n",
            "Vocab size: 257\n",
            "Vocab size: 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkCRaT7uJjML",
        "outputId": "c6bd9e28-bb05-4065-beb7-84f8eae185a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model import init_clip_model, load_clip_model\n",
        "from model import OnHWRTransformer\n",
        "from trainer import train, evaluate"
      ],
      "metadata": {
        "id": "rFNj-hESJneJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1xNin029kMH5OmC64M0bEt7aSdJM6ioTq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c4WIYohJsFa",
        "outputId": "a79d91ae-9bcc-4896-afc8-a472febdb3cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1xNin029kMH5OmC64M0bEt7aSdJM6ioTq\n",
            "From (redirected): https://drive.google.com/uc?id=1xNin029kMH5OmC64M0bEt7aSdJM6ioTq&confirm=t&uuid=e93ad8ec-3c32-43bc-b153-29998eb73cea\n",
            "To: /content/Handwritten-Mathematical-Expression-Recognition/latest_line_1_patch_16_9.pt\n",
            "100% 1.25G/1.25G [00:13<00:00, 92.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip_model = init_clip_model(device)\n",
        "clip_model = load_clip_model('latest_line_1_patch_16_9.pt', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1C1byiNJrjT",
        "outputId": "eb41a0bf-96a7-4820-8031-c9ac7b3dee61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 257\n",
            "Vocab size: 257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Handwritten-Mathematical-Expression-Recognition/model.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1hMVKCa84LLLj3_R6DcVtJRmV95YwTxFB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWcA3PvEKFHq",
        "outputId": "1086873b-8974-427b-f4dc-49802108a070"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1hMVKCa84LLLj3_R6DcVtJRmV95YwTxFB\n",
            "From (redirected): https://drive.google.com/uc?id=1hMVKCa84LLLj3_R6DcVtJRmV95YwTxFB&confirm=t&uuid=d03f851a-6a73-4e12-93ed-52e098b7acb1\n",
            "To: /content/Handwritten-Mathematical-Expression-Recognition/checkpoint_11_8_512_30.pth\n",
            "100% 327M/327M [00:01<00:00, 203MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_encoder_layers = 11\n",
        "nhead = 8\n",
        "d_model = 256\n",
        "dim_feedforward = 512\n",
        "vocab_size = 257\n",
        "\n",
        "model = OnHWRTransformer(vocab_size=vocab_size, clip_model=clip_model, d_model=d_model, nhead=nhead,\n",
        "                         num_encoder_layers=num_encoder_layers,\n",
        "                         dim_feedforward=dim_feedforward, dropout=0.1).to(device)\n",
        "\n",
        "checkpoint = torch.load(f'checkpoint_{num_encoder_layers}_{nhead}_{dim_feedforward}_{30}.pth',\n",
        "                        map_location=device)\n",
        "\n",
        "model.load_state_dict(checkpoint['model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mfuj2mgKAMa",
        "outputId": "a894a33d-e65f-4e59-ec84-be0b198d8e81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-14-e9667119a321>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(f'checkpoint_{num_encoder_layers}_{nhead}_{dim_feedforward}_{30}.pth',\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_cer = evaluate(model, valid_loader, device)\n",
        "print(valid_cer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8qqDDl6LHCE",
        "outputId": "136c4a3e-4e45-4efa-95c2-bce39c521b91"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7644/7644 [03:47<00:00, 33.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10472426033622718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5qfvH8ehMx0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}